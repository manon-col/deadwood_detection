{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cb1bf6",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\\\n",
    "The raw data are point clouds generated by MLS (mobile LiDAR). The very first preprocessing step involves processing by the SLAM algorithm (more specifically, via the application provided by GeoSLAM), and unzip files.\n",
    "\\\n",
    "Then, the next part consists in classifying ground points, generating a DTM, and extracting vegetation points in a slice parallel to DTM. This step is carried out using the opensource software Computree, and is detailed in the file computree_steps.xsct2 (it is ready to use, only the input files need to be selected and the output folder specified, parameters can also be viewed and modified).\n",
    "\\\n",
    "Note: depending on the device you are using, it may be necessary to tile the point cloud before processing with Computree. In this case, make sure you convert to point format 7 and merge the output tile files before moving on. I recommend using CloudCompare for tiling and for converting .laz to .las.\n",
    "\\\n",
    "*Output folder: 'computree_outputs'*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f008ba2",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\\\n",
    "*Input folder: 'computree_outputs'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77e5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages and modules\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "from clustering import ClEngine, Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21056ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computree_outputs\\\\07_04_ct.las', 'computree_outputs\\\\BM01_ct.las', 'computree_outputs\\\\BM02_ct.las', 'computree_outputs\\\\BM03_ct.las', 'computree_outputs\\\\BM04_ct.las', 'computree_outputs\\\\BM05_ct.las', 'computree_outputs\\\\BM06_ct.las', 'computree_outputs\\\\BM07_ct.las', 'computree_outputs\\\\BM08_ct.las']\n"
     ]
    }
   ],
   "source": [
    "las_files_path = 'computree_outputs' # location of preprocessed files\n",
    "clustered_files_path = 'cluster_outputs' # location of clustered files\n",
    "\n",
    "# Listing all .las files to cluster\n",
    "las_files = glob.glob('computree_outputs/*.las')\n",
    "print(las_files)\n",
    "\n",
    "# Listing clustered files\n",
    "clustered = glob.glob('cluster_outputs/*.las')\n",
    "clustered_names = [os.path.splitext(os.path.basename(file))[0] for file in clustered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e863ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File BM01_ct.las loaded successfully.\n",
      "Clustering BM01_ct.las points...\n"
     ]
    }
   ],
   "source": [
    "for file in las_files:\n",
    "    \n",
    "    # Checking if the file is not already clustered\n",
    "    if os.path.splitext(os.path.basename(file))[0]+'_clusters' not in clustered_names:\n",
    "        \n",
    "        cl = ClEngine(file)\n",
    "        \n",
    "        # Cluster .las file points\n",
    "        cl.DBSCAN_clustering(eps=0.05, min_samples=100) # distance parameters are in meters\n",
    "        \n",
    "        # Filter clusters given on a minimum number of points and minimum length\n",
    "        cl.filtering(nb_points=500, min_dist=1)\n",
    "        \n",
    "        # Draw a (very) basic representation of the clusters\n",
    "        cl.draw_clusters()\n",
    "        \n",
    "        # Save clustering results in new .las files (filename_clusters.las)\n",
    "        cl.save_clusters()\n",
    "        \n",
    "        # Clear memory\n",
    "        #del cl\n",
    "        #gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a975c2",
   "metadata": {},
   "source": [
    "# Cylinder fitting\n",
    "\\\n",
    "A RANSAC cylinder fitting operation must be carried out. Here, it is carried out in CloudCompare, with the following parameters:\n",
    "\\\n",
    "    - Minimum support points per primitive: 1000\n",
    "    - Use Least Squares fitting on found shapes\n",
    "    - Attempt to simplify shapes\n",
    "    - Set random color for each shape found\n",
    "    - Looking for cylinder primitives\n",
    "    Parameters\n",
    "    - Max distance to primitive: e = 0.1m\n",
    "    - Sampling resolution: b = 0.02\n",
    "    - Max normal deviation: a = 25.00Â°\n",
    "    - Overlooking probability: 0.0001\n",
    "    Cylinder advanced parameters\n",
    "    - Min radius: 0.03m\n",
    "    - Max radius: 0.5m\n",
    "\\\n",
    "This step is also a visual validation step.\n",
    "\\\n",
    "The point clouds of detected cylindrical shapes (not mesh !) must be exported in cloud ascii format (.txt), with headers as column titles. Make sure you save the multiple point clouds of the same study area in the same sub-folder.\n",
    "\n",
    "*Output folder: 'shapes_raw/sub-folder'*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f0b39",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "\\\n",
    "First, we need to create images from the previously generated points clouds of cylindrical shapes. The images are created from graphs in which the colour of the points depends on the z coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89724c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules\n",
    "import image_creation as imgcreate\n",
    "import image_classification as imgclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df945221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of folder with folders containing the files from which to create images\n",
    "path_raw = 'shapes_raw'\n",
    "\n",
    "# Path of folder containing image folders\n",
    "dataset_path = 'CNN_data'\n",
    "\n",
    "# Size of images\n",
    "image_size_inches = (4, 4) # in inches\n",
    "image_size = (217, 217) # in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccff43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse all files and create images from each file\n",
    "for folder in glob.glob(path_raw+'/*'):\n",
    "    \n",
    "    folder_name = os.path.splitext(os.path.basename(folder))[0]\n",
    "    dest = dataset_path + '/' + folder_name\n",
    "    \n",
    "    imgcreate.image_generator(data_folder=folder, img_folder=dest, figsize=image_size_inches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297be46",
   "metadata": {},
   "source": [
    "## Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'CNN_data/07_04' # location of image data to train the model\n",
    "\n",
    "train_ds, val_ds = imgclf.dataset_generation(folder)\n",
    "train_ds_augmented = imgclf.augmentation(train_ds)\n",
    "\n",
    "model = imgclf.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cb707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
