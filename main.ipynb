{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cb1bf6",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\\\n",
    "The raw data are point clouds generated by MLS (mobile LiDAR). The very first preprocessing step involves processing by the SLAM algorithm (more specifically, via the application provided by GeoSLAM), and unzip files.\n",
    "\n",
    "Then, the next part consists in classifying ground points, generating a DTM, and extracting vegetation points in a slice parallel to DTM. This step is carried out using the opensource software Computree, and is detailed in the file computree_steps.xsct2 (it is ready to use, only the input files need to be selected and the output folder specified, parameters can also be viewed and modified).\n",
    "\n",
    "Note: depending on the device you are using, it may be necessary to tile the point cloud before processing with Computree. In this case, make sure you convert to point format 7 and merge the output tile files before moving on. I recommend using CloudCompare for tiling and for converting .laz to .las.\n",
    "\n",
    "*Output folder: 'computree_outputs'*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f008ba2",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\\\n",
    "A shape (branch, trunk, etc.) is characterised by a high point density. To eliminate noise such as foliage, point clouds are clustered using a DBSCAN (density-based spatial clustering of applications with noise) algorithm. Clusters are then filtered in order to eliminate high branches, shapes that are mostly outside the inventory plot (radius 18m), shapes not long enough and remaining noise clusters with a low number of points.\n",
    "\n",
    "The clustering results are then exported as a point cloud (.las file), and as individual cluster images for classification.\n",
    "\n",
    "*Input folder: 'computree_outputs'*  \n",
    "*Output folders: 'clusters_las' (.las files), 'clusters_img' (.png files)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages and modules\n",
    "import os\n",
    "import glob\n",
    "from clustering import ClEngine, Cluster\n",
    "\n",
    "las_files_path = 'computree_outputs' # location of preprocessed files\n",
    "clusters_las_path = 'clusters_las' # location of clustered .las files\n",
    "clusters_img_path = 'clusters_img' # location of cluster images\n",
    "\n",
    "spheres_file = 'preprocessing/spheres_coordinates.csv' # file containing plot centre coordinates\n",
    "\n",
    "# Cluster image params\n",
    "figsize = (4,4)\n",
    "dpi = 75\n",
    "\n",
    "# Listing all .las files to cluster\n",
    "las_files = glob.glob('computree_outputs/*.las')\n",
    "\n",
    "# Listing already clustered files\n",
    "clustered = glob.glob(clusters_las_path + '/*.las')\n",
    "clustered_names = [os.path.splitext(os.path.basename(file))[0] for file in clustered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e863ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in las_files:\n",
    "    \n",
    "    # Checking if the file is not already clustered\n",
    "    if os.path.splitext(os.path.basename(file))[0]+'_clusters' not in clustered_names:\n",
    "        \n",
    "        cl = ClEngine(file)\n",
    "        \n",
    "        # Cluster .las file points\n",
    "        cl.DBSCAN_clustering(eps=0.05, min_samples=100) # distance parameters are in meters\n",
    "        \n",
    "        # Filter clusters given on a minimum number of points, distance from the plot centre, distance from the ground,\n",
    "        # and minimum length. Set argument to None to ignore filter. Note that the filter based on minimum length take\n",
    "        # a long time to process.\n",
    "        pla.filtering(nb_points=500,\n",
    "                      coord_file=spheres_file,\n",
    "                      sep=';',\n",
    "                      dec=',',\n",
    "                      distance_from_centre=18,\n",
    "                      delta=0.1,\n",
    "                      min_dist=None)\n",
    "        \n",
    "        # Draw a (very) basic representation of the clusters\n",
    "        # cl.draw_clusters()\n",
    "        \n",
    "        # Save clustering results in new .las files\n",
    "        cl.save_clusters_las(folder=clusters_las_path, suffix=\"clusters\")\n",
    "        \n",
    "        # Save clustering results in .png files\n",
    "        cl.save_clusters_img(folder=clusters_img_path, figsize=figsize, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297be46",
   "metadata": {},
   "source": [
    "## NNCLR model building\n",
    "\\\n",
    "The aim is not to spend our time manually classifying images, so we will be using a NNCLR model, adapted to a small labelled training set. The NNCLR model used here is based on the example of https://keras.io/examples/vision/nnclr/ (see link for more details).\n",
    "\n",
    "\n",
    "\n",
    "*Input/output folder: 'NNCLR_data', containing images for training*\n",
    "\n",
    "```\n",
    "NNCLR_data\n",
    "│\n",
    "├── labelled\n",
    "│   ├── deadwood\n",
    "│   │   ├── image1.png\n",
    "│   │   ├── image2.png\n",
    "│   │   ├── ...\n",
    "│   │\n",
    "│   └── other\n",
    "│       ├── image1.png\n",
    "│       ├── image2.png\n",
    "│       ├── ...\n",
    "│\n",
    "└── unlabelled\n",
    "    └── unlabelled\n",
    "        ├── image1.png\n",
    "        ├── image2.png\n",
    "        ├── ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import image_classification as imgclf\n",
    "\n",
    "# device = 'CPU:0' # device used to run tensorflow\n",
    "model_path = 'NNCLR_data' # path with labelled and unlabelled images for training\n",
    "save_path = model_path + '/finetuning_model'\n",
    "batch_size = 32\n",
    "num_epochs = 50 # max number of epochs, the model will stop automatically when val_p_loss has not increased for 5 epochs\n",
    "image_size = (300, 300) # in pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e132af0",
   "metadata": {},
   "source": [
    "If GPU memory is insufficient, the CPU can be used (calculations will take longer). Use :\n",
    "\n",
    "```\n",
    "with tf.device('CPU:0'):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Model hyperparameters, for information:\n",
    "\n",
    "```\n",
    "input_shape = (image_size[0], image_size[1], 3)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "shuffle_buffer = 5000   \n",
    "temperature = 0.1\n",
    "queue_size = 10000\n",
    "contrastive_augmenter = {\n",
    "    \"brightness\": 0.5,\n",
    "    \"name\": \"contrastive_augmenter\",\n",
    "    \"scale\": (0.2, 1.0)}\n",
    "classification_augmenter = {\n",
    "    \"brightness\": 0.2,\n",
    "    \"name\": \"classification_augmenter\",\n",
    "    \"scale\": (0.5, 1.0)}\n",
    "width = 128\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7701e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model\n",
    "model = imgclf.Model(model_path, image_size, batch_size, num_epochs)\n",
    "\n",
    "# Prepare training and validation datasets\n",
    "model.prepare_dataset()\n",
    "\n",
    "# Pre-train NNCLR\n",
    "model.pretraining()\n",
    "    \n",
    "# Evaluate the model\n",
    "model.finetuning(save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f869e",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\\\n",
    "*Input folders: 'NNCLR_data', 'clusters_las', 'clusters_img'*  \n",
    "*Output folder: 'deadwood'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import laspy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import image_classification as imgclf\n",
    "from clustering import ClEngine, Cluster, label_from\n",
    "\n",
    "# Needed paths\n",
    "model_path = 'NNCLR_data'\n",
    "save_path = model_path + '/finetuning_model'\n",
    "path_las = 'clusters_las'\n",
    "path_img = 'clusters_img'\n",
    "path_dw = 'deadwood'\n",
    "\n",
    "# Same as before\n",
    "#device = 'CPU:0'\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "image_size = (300, 300)\n",
    "\n",
    "# Get already classified file names\n",
    "classified_files = glob.glob(path_dw+'/*.las')\n",
    "classified_names = [os.path.splitext(os.path.basename(file))[0] for file in classified_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create model\n",
    "model = imgclf.Model(model_path, image_size, batch_size, num_epochs)\n",
    "model.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse of each study area folder\n",
    "for folder in glob.glob(path_img+'/*'):\n",
    "    \n",
    "    folder_name = os.path.splitext(os.path.basename(folder))[0]\n",
    "    \n",
    "    #Check if classification is not already done\n",
    "    if folder_name + '_deadwood' not in classified_names:\n",
    "        \n",
    "        print(\"Classifying \" + folder_name + \" images.\")\n",
    "        \n",
    "        las_file = path_las + '/' + folder_name + '.las'\n",
    "        \n",
    "        # Load clusters\n",
    "        cl = ClEngine(las_file)\n",
    "        tot = len(cl.get_clusters()) # initial number of clusters\n",
    "        \n",
    "        # List of cluster images\n",
    "        images = glob.glob(folder+'/*.png')\n",
    "        \n",
    "        # Make a prediction with the model: each image classified as deadwood by the model, and\n",
    "        # classified as \"other\" but with a score < threshold are kept in the final point cloud\n",
    "        deadwood_images = model.prediction(images, threshold=None)\n",
    "        \n",
    "        # List of clusters (cluster labels) classified as deadwood\n",
    "        deadwood_labels = [label_from(image) for image in deadwood_images]\n",
    "        \n",
    "        # Keep clusters classified as deadwood\n",
    "        cl.keep_clusters(cluster_list=deadwood_labels)\n",
    "        \n",
    "        # Save clusters classified as deadwood\n",
    "        cl.save_clusters_las(path_dw, suffix='deadwood')\n",
    "        \n",
    "        print(f\"{len(deadwood_labels)} clusters classified as deadwood out of {tot}.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da810229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
